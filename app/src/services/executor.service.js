const logger = require('logger');
const statusQueueService = require('services/status-queue.service');
const { execution } = require('doc-importer-messages');
const ImporterService = require('services/importer.service');
const elasticService = require('services/elastic.service');
const UrlNotFound = require('errors/urlNotFound');

const ExecutionMessages = execution.MESSAGE_TYPES;

const sleep = time => new Promise(resolve => setTimeout(resolve, time));

class ExecutorService {

    static async processMessage(msg) {
        logger.debug('Processing message', msg);
        switch (msg.type) {

        case ExecutionMessages.EXECUTION_CREATE:
            await ExecutorService.create(msg);
            break;

        case ExecutionMessages.EXECUTION_CONCAT:
            await ExecutorService.concat(msg);
            break;

        case ExecutionMessages.EXECUTION_DELETE:
            await ExecutorService.deleteQuery(msg);
            break;

        case ExecutionMessages.EXECUTION_CONFIRM_DELETE:
            await ExecutorService.confirmDelete(msg);
            break;

        case ExecutionMessages.EXECUTION_DELETE_INDEX:
            await ExecutorService.deleteIndex(msg);
            break;

        case ExecutionMessages.EXECUTION_CONFIRM_IMPORT:
            await ExecutorService.confirmImport(msg);
            break;

        case ExecutionMessages.EXECUTION_CONFIRM_REINDEX:
            await ExecutorService.confirmReIndex(msg);
            break;

        case ExecutionMessages.EXECUTION_REINDEX:
            await ExecutorService.reindex(msg);
            break;


        default:
            logger.error('Message not supported');

        }
    }

    static async create(msg) {
        // Create the index
        logger.debug('Create task');
        logger.debug('Creating index');
        const index = `index_${msg.datasetId.replace(/-/g, '')}_${Date.now()}`;
        await elasticService.createIndex(index, msg.legend);
        await elasticService.deactivateIndex(index);
        msg.index = index;
        // Now send a STATUS_INDEX_CREATED to StatusQueue
        await statusQueueService.sendIndexCreated(msg.taskId, index);
        logger.debug('Starting importing service');
        try {
            const importerService = new ImporterService(msg);
            await importerService.start();
            logger.debug('Sending read file message');
            await statusQueueService.sendReadFile(msg.taskId);
        } catch (err) {
            if (err instanceof UrlNotFound) {
                statusQueueService.sendErrorMessage(msg.taskId, err.message);
                return;
            }
            throw err;
        }
    }

    static async concat(msg) {
        // The Index is already craeted when concatenating
        logger.debug('Starting importing service');
        logger.debug('Creating index');
        const index = `index_${msg.datasetId.replace(/-/g, '')}_${Date.now()}`;
        await elasticService.createIndex(index, msg.index, msg.legend);
        await elasticService.deactivateIndex(index);
        msg.index = index;
        // Now send a STATUS_INDEX_CREATED to StatusQueue
        await statusQueueService.sendIndexCreated(msg.taskId, index);
        logger.debug('Starting importing service');
        try {
            const importerService = new ImporterService(msg);
            await importerService.start();
            logger.debug('Sending read file message');
            await statusQueueService.sendReadFile(msg.taskId);
        } catch (err) {
            if (err instanceof UrlNotFound) {
                statusQueueService.sendErrorMessage(msg.taskId, err.message);
                return;
            }
            throw err;
        }
    }

    static async deleteQuery(msg) {
        logger.debug('Delete data of index with query ', msg.query);
        const elasticTaskId = await elasticService.deleteQuery(msg.index, msg.query);
        // Generate Performed Delete Query event
        await statusQueueService.sendPerformedDeleteQuery(msg.taskId, elasticTaskId);
    }

    static async reindex(msg) {
        logger.debug(`Reindex from index ${msg.sourceIndex} to index ${msg.targetIndex}`);
        const elasticTaskId = await elasticService.reindex(msg.sourceIndex, msg.targetIndex);
        // Generate Performed Delete Query event
        await statusQueueService.sendPerformedReindex(msg.taskId, elasticTaskId);
    }

    static async confirmDelete(msg) {
        logger.debug('Confirm Delete data with elastictaskid ', msg.elasticTaskId);
        const finished = await elasticService.checkFinishTaskId(msg.elasticTaskId);
        if (!finished) {
            await sleep(2000);
            throw new Error('Task not finished');
        }
        // try {check elasticTask } catch (err) throw new Error
        // throwing an error here implies that the msg is going to
        // be "nacked"
        // set a timeout before throw the error
        // if not an error
        await statusQueueService.sendFinishedDeleteQuery(msg.taskId);
    }

    static async confirmReIndex(msg) {
        logger.debug('Confirm Reindex data with elastictaskid ', msg.elasticTaskId);
        const finished = await elasticService.checkFinishTaskId(msg.elasticTaskId);
        if (!finished) {
            await sleep(2000);
            throw new Error('Task not finished');
        }

        await statusQueueService.sendFinishedReindex(msg.taskId);
    }

    static async deleteIndex(msg) {
        logger.debug('Deleting index', msg.index);
        await elasticService.deleteIndex(msg.index);
        await statusQueueService.sendIndexDeleted(msg.taskId);
    }

    static async confirmImport(msg) {
        logger.debug('Confirming index', msg.index);
        await elasticService.activateIndex(msg.index);
        await statusQueueService.sendImportConfirmed(msg.taskId);
    }

}

module.exports = ExecutorService;
